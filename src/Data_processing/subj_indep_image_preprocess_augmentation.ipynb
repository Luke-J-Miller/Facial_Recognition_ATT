{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c045f61",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-07T18:42:57.653660Z",
     "iopub.status.busy": "2023-12-07T18:42:57.653155Z",
     "iopub.status.idle": "2023-12-07T18:43:15.797207Z",
     "shell.execute_reply": "2023-12-07T18:43:15.795812Z"
    },
    "papermill": {
     "duration": 18.157657,
     "end_time": "2023-12-07T18:43:15.800077",
     "exception": false,
     "start_time": "2023-12-07T18:42:57.642420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd \n",
    "import tensorflow.compat.v1 as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "tf.disable_eager_execution()\n",
    "import tensorflow_hub as hub\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d638d",
   "metadata": {
    "papermill": {
     "duration": 0.005678,
     "end_time": "2023-12-07T18:43:15.812011",
     "exception": false,
     "start_time": "2023-12-07T18:43:15.806333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Notes\n",
    "Georgia Tech face database (128Mb) contains images of 50 people taken in two \n",
    "or three sessions between 06/01/99 and 11/15/99 at the Center for Signal and \n",
    "Image Processing at  Georgia Institute of Technology. All people in the database \n",
    "are represented by 15 color JPEG images with cluttered background taken at resolution \n",
    "640x480 pixels. The average size of the faces in these images is 150x150 pixels. \n",
    "The images are stored in 50 directories s1, ..., s50. In each directory there \n",
    "are 15 images 01.jpg, ..., 15.jpg corresponding to one person in the database. \n",
    "\n",
    "Each image is manually labeled to determine the position of the face in the image.\n",
    "The label files contain four integers that describe the coordinates of the face rectangles \n",
    "and a string (s1, ..., s50) indicating the identity of the face. Assuming that the upper \n",
    "left corner of the image has the coordinates (0,0), the numbers correspond to the \n",
    "x_left, y_top, x_right, y_bottom coordinates of the face rectangle. \n",
    "\n",
    "The label files are named as follows: \n",
    "lab001-lab015 correspond to files 01.jpg,...,15.jpg  in s01\n",
    "lab021-lab035 correspond to files 01.jpg,...,15.jpg  in s02\n",
    "lab041-lab055 correspond to files 01.jpg,...,15.jpg  in s03\n",
    "lab061-lab075 correspond to files 01.jpg,...,15.jpg  in s04\n",
    "....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4659d82d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:43:15.827007Z",
     "iopub.status.busy": "2023-12-07T18:43:15.825328Z",
     "iopub.status.idle": "2023-12-07T18:43:15.834072Z",
     "shell.execute_reply": "2023-12-07T18:43:15.832819Z"
    },
    "papermill": {
     "duration": 0.019152,
     "end_time": "2023-12-07T18:43:15.837045",
     "exception": false,
     "start_time": "2023-12-07T18:43:15.817893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_image_grid(image_paths, rows=4, cols=4):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')  # Turn off axis numbers and labels\n",
    "        axes[i].set_title(img_path.split('/')[-1])  # Optional: Set titles as filenames\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebc50ace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:43:15.851325Z",
     "iopub.status.busy": "2023-12-07T18:43:15.850840Z",
     "iopub.status.idle": "2023-12-07T18:43:15.861867Z",
     "shell.execute_reply": "2023-12-07T18:43:15.860531Z"
    },
    "papermill": {
     "duration": 0.021143,
     "end_time": "2023-12-07T18:43:15.864416",
     "exception": false,
     "start_time": "2023-12-07T18:43:15.843273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_image(image_path, target_size=(299, 299)):\n",
    "    with Image.open(image_path) as img:\n",
    "        old_size = img.size\n",
    "\n",
    "        # Calculate the new size, maintaining the aspect ratio\n",
    "        ratio = float(target_size[0])/max(old_size)\n",
    "        new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "        img = img.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "        # Calculate the deltas for padding\n",
    "        delta_w = target_size[0] - new_size[0]\n",
    "        delta_h = target_size[1] - new_size[1]\n",
    "\n",
    "        # Create a new image with the target size and paste the resized image onto it\n",
    "        new_img = Image.new(\"RGB\", target_size)\n",
    "        new_img.paste(img, ((target_size[0] - new_size[0]) // 2,\n",
    "                            (target_size[1] - new_size[1]) // 2))\n",
    "\n",
    "        # Edge padding\n",
    "        left, top, right, bottom = ((target_size[0] - new_size[0]) // 2,\n",
    "                                    (target_size[1] - new_size[1]) // 2,\n",
    "                                    (target_size[0] - new_size[0] - (target_size[0] - new_size[0]) // 2),\n",
    "                                    (target_size[1] - new_size[1] - (target_size[1] - new_size[1]) // 2))\n",
    "        \n",
    "        new_img = ImageOps.expand(new_img, border=(left, top, right, bottom), fill=None)\n",
    "\n",
    "        return np.array(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5b40c1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:43:15.878651Z",
     "iopub.status.busy": "2023-12-07T18:43:15.878183Z",
     "iopub.status.idle": "2023-12-07T18:43:15.886451Z",
     "shell.execute_reply": "2023-12-07T18:43:15.885223Z"
    },
    "papermill": {
     "duration": 0.018334,
     "end_time": "2023-12-07T18:43:15.888874",
     "exception": false,
     "start_time": "2023-12-07T18:43:15.870540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_subjects():\n",
    "    source_dir = '/kaggle/input/cs5567-final/GTdb_crop/cropped_faces'\n",
    "    destination_dir = 'organized_faces'\n",
    "\n",
    "    # Create destination directory if it doesn't exist\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    # Iterate over all files in the source directory\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            # Extract subject identifier from the filename\n",
    "            subject_id = filename.split('_')[0]\n",
    "            \n",
    "            # Create a directory for the subject if it doesn't exist\n",
    "            subject_dir = os.path.join(destination_dir, subject_id)\n",
    "            if not os.path.exists(subject_dir):\n",
    "                os.makedirs(subject_dir)\n",
    "\n",
    "            # Move the file to the subject's directory\n",
    "            shutil.copy(os.path.join(source_dir, filename), os.path.join(subject_dir, filename))\n",
    "            #print(f'{filename} generated subject {subject_id} and directory {subject_dir}')\n",
    "    print(\"Images have been sorted into subject folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6e5234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:43:15.902780Z",
     "iopub.status.busy": "2023-12-07T18:43:15.902356Z",
     "iopub.status.idle": "2023-12-07T18:43:15.913598Z",
     "shell.execute_reply": "2023-12-07T18:43:15.912209Z"
    },
    "papermill": {
     "duration": 0.021766,
     "end_time": "2023-12-07T18:43:15.916618",
     "exception": false,
     "start_time": "2023-12-07T18:43:15.894852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    data_dir = '/kaggle/working/organized_faces'\n",
    "    base_dir = 'split_faces'\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    val_dir = os.path.join(base_dir, 'val')\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "    # Create base directories if they don't exist\n",
    "    for directory in [train_dir, val_dir, test_dir]:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "    # Function to copy files to the respective directories\n",
    "    def copy_files(files, dest_dir, subject_folder):\n",
    "        subject_dest_dir = os.path.join(dest_dir, subject_folder)\n",
    "        if not os.path.exists(subject_dest_dir):\n",
    "            os.makedirs(subject_dest_dir)\n",
    "        for file in files:\n",
    "            src_file_path = os.path.join(data_dir, subject_folder, file)\n",
    "            dest_file_path = os.path.join(subject_dest_dir, file)\n",
    "            shutil.copy(src_file_path, dest_file_path)\n",
    "\n",
    "    subjects = sorted(os.listdir(data_dir))  # Sort the subjects to ensure consistency\n",
    "    test_subjects = subjects[-10:]  # Last 10 subjects for the test set\n",
    "    train_val_subjects = subjects[:-10]  # First 40 subjects for train and val sets\n",
    "\n",
    "    # Split the test set\n",
    "    for subject in test_subjects:\n",
    "        subject_path = os.path.join(data_dir, subject)\n",
    "        test_images = os.listdir(subject_path)\n",
    "        copy_files(test_images, test_dir, subject)\n",
    "\n",
    "    # Split the train and val sets\n",
    "    for subject in train_val_subjects:\n",
    "        subject_path = os.path.join(data_dir, subject)\n",
    "        images = os.listdir(subject_path)\n",
    "        train_images, val_images = train_test_split(images, test_size=0.2, random_state=42)  # 80-20 split\n",
    "        copy_files(train_images, train_dir, subject)\n",
    "        copy_files(val_images, val_dir, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7133be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:43:15.931188Z",
     "iopub.status.busy": "2023-12-07T18:43:15.930638Z",
     "iopub.status.idle": "2023-12-07T18:43:15.945255Z",
     "shell.execute_reply": "2023-12-07T18:43:15.944028Z"
    },
    "papermill": {
     "duration": 0.024842,
     "end_time": "2023-12-07T18:43:15.948023",
     "exception": false,
     "start_time": "2023-12-07T18:43:15.923181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment_data(train_datagen):\n",
    "    def resize_with_padding(img, target_size=(299, 299)):\n",
    "        # Resize the image while maintaining aspect ratio\n",
    "        ratio = min(target_size[0] / img.size[0], target_size[1] / img.size[1])\n",
    "        new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))\n",
    "        img = img.resize(new_size, Image.ANTIALIAS)\n",
    "\n",
    "        # Convert to numpy array for ease of calculation\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Calculate the average color of the leftmost and rightmost columns\n",
    "        left_margin = img_array[:, 0, :]\n",
    "        right_margin = img_array[:, -1, :]\n",
    "        avg_color = np.mean(np.concatenate([left_margin, right_margin]), axis=0, dtype=int)\n",
    "\n",
    "        # Create a new image with the average color of the margins\n",
    "        new_img = Image.new(\"RGB\", target_size, tuple(avg_color))\n",
    "        top_left_x = (target_size[0] - new_size[0]) // 2\n",
    "        top_left_y = (target_size[1] - new_size[1]) // 2\n",
    "        new_img.paste(img, (top_left_x, top_left_y))\n",
    "\n",
    "        return new_img\n",
    "    np.random.seed(42)\n",
    "\n",
    "    directories = {\n",
    "        'train': '/kaggle/working/split_faces/train',\n",
    "        'test': '/kaggle/working/split_faces/test',\n",
    "        'val': '/kaggle/working/split_faces/val'\n",
    "    }\n",
    "\n",
    "    augmented_dir = 'augmented_faces'\n",
    "\n",
    "    for dir_type, dir_path in directories.items():\n",
    "        for subject in os.listdir(dir_path):\n",
    "            subject_dir = os.path.join(dir_path, subject)\n",
    "            augmented_subject_dir = os.path.join(augmented_dir, dir_type, subject)\n",
    "\n",
    "            if not os.path.exists(augmented_subject_dir):\n",
    "                os.makedirs(augmented_subject_dir)\n",
    "\n",
    "            for img_file in os.listdir(subject_dir):\n",
    "                img_path = os.path.join(subject_dir, img_file)\n",
    "                img = Image.open(img_path)\n",
    "                img = resize_with_padding(img, (299, 299))\n",
    "                img_array = img_to_array(img)\n",
    "                img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "                file_name_without_ext = os.path.splitext(img_file)[0]\n",
    "\n",
    "                if dir_type == 'train':\n",
    "                    # Apply augmentation for training images\n",
    "                    i = 0\n",
    "                    for batch in train_datagen.flow(img_array, batch_size=1,\n",
    "                                                    save_to_dir=augmented_subject_dir,\n",
    "                                                    save_prefix=file_name_without_ext + '_',\n",
    "                                                    save_format='jpg'):\n",
    "                        i += 1\n",
    "                        if i >= 5:\n",
    "                            break\n",
    "                else:\n",
    "                    # For test and val, only resize and save the image\n",
    "                    img.save(os.path.join(augmented_subject_dir, f\"{file_name_without_ext}.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a804bc6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:43:15.962154Z",
     "iopub.status.busy": "2023-12-07T18:43:15.961645Z",
     "iopub.status.idle": "2023-12-07T18:43:15.997134Z",
     "shell.execute_reply": "2023-12-07T18:43:15.996091Z"
    },
    "papermill": {
     "duration": 0.045819,
     "end_time": "2023-12-07T18:43:15.999792",
     "exception": false,
     "start_time": "2023-12-07T18:43:15.953973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shape is: Width = 181, Height = 241\n",
      "Number of channels: 3\n"
     ]
    }
   ],
   "source": [
    "# Open an image\n",
    "image = Image.open('/kaggle/input/cs5567-final/GTdb_crop/cropped_faces/s01_01.jpg')\n",
    "\n",
    "# Get image size\n",
    "width, height = image.size\n",
    "\n",
    "print(f\"The image shape is: Width = {width}, Height = {height}\")\n",
    "\n",
    "# Note: PIL does not provide the number of channels directly, but you can get it like this:\n",
    "channels = len(image.getbands())\n",
    "print(f\"Number of channels: {channels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9473b998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:43:16.014608Z",
     "iopub.status.busy": "2023-12-07T18:43:16.014107Z",
     "iopub.status.idle": "2023-12-07T18:43:21.143097Z",
     "shell.execute_reply": "2023-12-07T18:43:21.141781Z"
    },
    "papermill": {
     "duration": 5.139323,
     "end_time": "2023-12-07T18:43:21.145712",
     "exception": false,
     "start_time": "2023-12-07T18:43:16.006389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have been sorted into subject folders.\n"
     ]
    }
   ],
   "source": [
    "group_subjects()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e49f0ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-06T16:38:19.433046Z",
     "iopub.status.busy": "2023-12-06T16:38:19.432431Z",
     "iopub.status.idle": "2023-12-06T16:38:25.248959Z",
     "shell.execute_reply": "2023-12-06T16:38:25.247544Z",
     "shell.execute_reply.started": "2023-12-06T16:38:19.433015Z"
    },
    "papermill": {
     "duration": 0.005753,
     "end_time": "2023-12-07T18:43:21.157928",
     "exception": false,
     "start_time": "2023-12-07T18:43:21.152175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "image_dir = '/kaggle/input/cs5567-final/GTdb_crop/cropped_faces'\n",
    "padded_dir = 'padded_faces'\n",
    "label_dir = '/kaggle/input/cs5567-final/labels_gt/labels'\n",
    "\n",
    "# Create padded image directory if it doesn't exist\n",
    "if not os.path.exists(padded_dir):\n",
    "    os.makedirs(padded_dir)\n",
    "\n",
    "# Iterate through each image file in the directory\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.jpg'):  # Assuming images are in .jpg format\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        padded_image = pad_image(image_path)\n",
    "\n",
    "        # Convert back to PIL image and save\n",
    "        pil_image = Image.fromarray(padded_image)\n",
    "        save_path = os.path.join(padded_dir, filename)\n",
    "        pil_image.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1592c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:43:21.172833Z",
     "iopub.status.busy": "2023-12-07T18:43:21.172069Z",
     "iopub.status.idle": "2023-12-07T18:43:21.300238Z",
     "shell.execute_reply": "2023-12-07T18:43:21.298961Z"
    },
    "papermill": {
     "duration": 0.139007,
     "end_time": "2023-12-07T18:43:21.303221",
     "exception": false,
     "start_time": "2023-12-07T18:43:21.164214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f65dd4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:43:21.317592Z",
     "iopub.status.busy": "2023-12-07T18:43:21.317128Z",
     "iopub.status.idle": "2023-12-07T18:43:21.323715Z",
     "shell.execute_reply": "2023-12-07T18:43:21.322561Z"
    },
    "papermill": {
     "duration": 0.01664,
     "end_time": "2023-12-07T18:43:21.326054",
     "exception": false,
     "start_time": "2023-12-07T18:43:21.309414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,             # Random rotation between -15 to 15 degrees\n",
    "    width_shift_range=0.05,         # Horizontal shift, here 10% of the total width\n",
    "    height_shift_range=0.05,        # Vertical shift, here 10% of the total height\n",
    "    brightness_range=(0.2, 0.2),         # No brightness adjustment\n",
    "    shear_range=0.0,               # No shear transformation\n",
    "    zoom_range=0.05,                # No zoom\n",
    "    channel_shift_range=20,       # No channel shift\n",
    "    fill_mode='nearest',           # Fill strategy for new pixels after rotation/shift\n",
    "    cval=0.0,                      # Value used for fill_mode=\"constant\"\n",
    "    horizontal_flip=False,         # No horizontal flip\n",
    "    vertical_flip=False,           # No vertical flip\n",
    "    rescale=None,                  # No rescaling factor (e.g., rescale=1./255)\n",
    "    preprocessing_function=None,   # No preprocessing function\n",
    "    data_format=None,              # Default data format\n",
    "    validation_split=0.0,          # No validation split\n",
    "    interpolation_order=1,         # Default interpolation order\n",
    "    dtype=None                     # Default data type\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aa68c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:43:21.339978Z",
     "iopub.status.busy": "2023-12-07T18:43:21.339561Z",
     "iopub.status.idle": "2023-12-07T18:44:31.494588Z",
     "shell.execute_reply": "2023-12-07T18:44:31.493598Z"
    },
    "papermill": {
     "duration": 70.165482,
     "end_time": "2023-12-07T18:44:31.497693",
     "exception": false,
     "start_time": "2023-12-07T18:43:21.332211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/2788992328.py:6: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize(new_size, Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "augment_data(train_datagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7474d5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-06T17:57:42.335724Z",
     "iopub.status.busy": "2023-12-06T17:57:42.334834Z",
     "iopub.status.idle": "2023-12-06T17:57:42.343405Z",
     "shell.execute_reply": "2023-12-06T17:57:42.342048Z",
     "shell.execute_reply.started": "2023-12-06T17:57:42.335669Z"
    },
    "papermill": {
     "duration": 0.005759,
     "end_time": "2023-12-07T18:44:31.509934",
     "exception": false,
     "start_time": "2023-12-07T18:44:31.504175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Open an image\n",
    "image = Image.open('/kaggle/working/augmented_faces/train/s01/s01_13__0_5161.jpg')\n",
    "\n",
    "# Get image size\n",
    "width, height = image.size\n",
    "\n",
    "print(f\"The image shape is: Width = {width}, Height = {height}\")\n",
    "\n",
    "# Note: PIL does not provide the number of channels directly, but you can get it like this:\n",
    "channels = len(image.getbands())\n",
    "print(f\"Number of channels: {channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4d4337",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-06T18:05:51.699946Z",
     "iopub.status.busy": "2023-12-06T18:05:51.699424Z",
     "iopub.status.idle": "2023-12-06T18:05:54.263682Z",
     "shell.execute_reply": "2023-12-06T18:05:54.26266Z",
     "shell.execute_reply.started": "2023-12-06T18:05:51.69991Z"
    },
    "papermill": {
     "duration": 0.005742,
     "end_time": "2023-12-07T18:44:31.521791",
     "exception": false,
     "start_time": "2023-12-07T18:44:31.516049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "image_files = [\n",
    "    \"/kaggle/working/split_faces/train/s33/s33_08.jpg\",\n",
    "    \"/kaggle/working/augmented_faces/train/s33/s33_08__0_5486.jpg\",\n",
    "    \"/kaggle/working/augmented_faces/train/s33/s33_08__0_8666.jpg\",\n",
    "    \"/kaggle/working/augmented_faces/train/s33/s33_08__0_8322.jpg\",\n",
    "\n",
    "    \"/kaggle/working/split_faces/train/s40/s40_12.jpg\",\n",
    "    \"/kaggle/working/augmented_faces/train/s40/s40_12__0_9347.jpg\",\n",
    "    \"/kaggle/working/augmented_faces/train/s40/s40_12__0_5348.jpg\",\n",
    "    \"/kaggle/working/augmented_faces/train/s40/s40_12__0_4849.jpg\",\n",
    "\n",
    "    \"/kaggle/working/split_faces/train/s36/s36_12.jpg\",\n",
    "    \"/kaggle/working/augmented_faces/train/s36/s36_12__0_3876.jpg\",\n",
    "    \"/kaggle/working/augmented_faces/train/s36/s36_12__0_345.jpg\",\n",
    "    \"/kaggle/working/augmented_faces/train/s36/s36_12__0_8393.jpg\",\n",
    "    \n",
    "    \"/kaggle/working/split_faces/train/s28/s28_08.jpg\",\n",
    "    \"/kaggle/working/augmented_faces/train/s28/s28_08__0_9098.jpg\",\n",
    "    \"/kaggle/working/augmented_faces/train/s28/s28_08__0_988.jpg\",\n",
    "    \"/kaggle/working/augmented_faces/train/s28/s28_08__0_9437.jpg\"\n",
    "]\n",
    "\n",
    "# Call the function to display the images\n",
    "display_image_grid(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbeca0e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:44:31.536210Z",
     "iopub.status.busy": "2023-12-07T18:44:31.535232Z",
     "iopub.status.idle": "2023-12-07T18:44:31.543320Z",
     "shell.execute_reply": "2023-12-07T18:44:31.542298Z"
    },
    "papermill": {
     "duration": 0.01804,
     "end_time": "2023-12-07T18:44:31.545850",
     "exception": false,
     "start_time": "2023-12-07T18:44:31.527810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(directory):\n",
    "    def extract_label(file_path):\n",
    "        \"\"\"\n",
    "        Extract the subject label from the file path.\n",
    "        Example: '/path/to/s01/image.jpg' -> 's01'\n",
    "        \"\"\"\n",
    "        return os.path.basename(os.path.dirname(file_path))\n",
    "    images = []\n",
    "    labels = []\n",
    "    for folder in os.listdir(directory):\n",
    "        folder_path = os.path.join(directory, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                # Load and preprocess the image\n",
    "                image = load_img(file_path, target_size=(299, 299))  # Resize as per Inception V3 input\n",
    "                image = img_to_array(image)\n",
    "                image /= 255.0  # Normalize to [0, 1]\n",
    "                \n",
    "                images.append(image)\n",
    "                labels.append(extract_label(file_path))\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "126e0788",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:44:31.560937Z",
     "iopub.status.busy": "2023-12-07T18:44:31.560499Z",
     "iopub.status.idle": "2023-12-07T18:44:38.871454Z",
     "shell.execute_reply": "2023-12-07T18:44:38.870440Z"
    },
    "papermill": {
     "duration": 7.321651,
     "end_time": "2023-12-07T18:44:38.874152",
     "exception": false,
     "start_time": "2023-12-07T18:44:31.552501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dir = '/kaggle/working/augmented_faces/train'\n",
    "train_images, train_labels = load_dataset(train_dir)\n",
    "\n",
    "# Convert labels to numerical format\n",
    "label_to_num = {label: idx for idx, label in enumerate(np.unique(train_labels))}\n",
    "num_labels = len(label_to_num)\n",
    "\n",
    "train_labels_num = np.array([label_to_num[label] for label in train_labels])\n",
    "\n",
    "# One-hot encode labels\n",
    "train_labels_encoded = to_categorical(train_labels_num, num_classes=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9c00829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:44:38.888724Z",
     "iopub.status.busy": "2023-12-07T18:44:38.888267Z",
     "iopub.status.idle": "2023-12-07T18:44:45.298677Z",
     "shell.execute_reply": "2023-12-07T18:44:45.297488Z"
    },
    "papermill": {
     "duration": 6.421032,
     "end_time": "2023-12-07T18:44:45.301501",
     "exception": false,
     "start_time": "2023-12-07T18:44:38.880469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dir = '/kaggle/working/augmented_faces/test'\n",
    "test_images, test_labels = load_dataset(train_dir)\n",
    "\n",
    "# Convert labels to numerical format\n",
    "label_to_num = {label: idx for idx, label in enumerate(np.unique(test_labels))}\n",
    "num_labels = len(label_to_num)\n",
    "\n",
    "test_labels_num = np.array([label_to_num[label] for label in test_labels])\n",
    "\n",
    "# One-hot encode labels\n",
    "test_labels_encoded = to_categorical(test_labels_num, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34b51b19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:44:45.315797Z",
     "iopub.status.busy": "2023-12-07T18:44:45.315013Z",
     "iopub.status.idle": "2023-12-07T18:44:45.604198Z",
     "shell.execute_reply": "2023-12-07T18:44:45.602867Z"
    },
    "papermill": {
     "duration": 0.299653,
     "end_time": "2023-12-07T18:44:45.607241",
     "exception": false,
     "start_time": "2023-12-07T18:44:45.307588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dir = '/kaggle/working/augmented_faces/val'\n",
    "val_images, val_labels = load_dataset(val_dir)\n",
    "\n",
    "# Convert labels to numerical format\n",
    "label_to_num = {label: idx for idx, label in enumerate(np.unique(val_labels))}\n",
    "num_labels = len(label_to_num)\n",
    "\n",
    "val_labels_num = np.array([label_to_num[label] for label in val_labels])\n",
    "\n",
    "# One-hot encode labels\n",
    "val_labels_encoded = to_categorical(val_labels_num, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "735243ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T18:44:45.621840Z",
     "iopub.status.busy": "2023-12-07T18:44:45.621416Z",
     "iopub.status.idle": "2023-12-07T18:44:53.835760Z",
     "shell.execute_reply": "2023-12-07T18:44:53.834305Z"
    },
    "papermill": {
     "duration": 8.225575,
     "end_time": "2023-12-07T18:44:53.839137",
     "exception": false,
     "start_time": "2023-12-07T18:44:45.613562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a directory for saving numpy data if it doesn't exist\n",
    "if not os.path.exists('numpy_data'):\n",
    "    os.makedirs('numpy_data')\n",
    "\n",
    "# Define the base directory path\n",
    "base_dir = 'numpy_data'\n",
    "\n",
    "# For Training Data\n",
    "np.save(os.path.join(base_dir, 'train_images.npy'), train_images)\n",
    "np.save(os.path.join(base_dir, 'train_labels_num.npy'), train_labels_num)\n",
    "np.save(os.path.join(base_dir, 'train_labels_encoded.npy'), train_labels_encoded)\n",
    "\n",
    "# For Test Data\n",
    "np.save(os.path.join(base_dir, 'test_images.npy'), test_images)\n",
    "np.save(os.path.join(base_dir, 'test_labels_num.npy'), test_labels_num)\n",
    "np.save(os.path.join(base_dir, 'test_labels_encoded.npy'), test_labels_encoded)\n",
    "\n",
    "# For Validation Data\n",
    "np.save(os.path.join(base_dir, 'val_images.npy'), val_images)\n",
    "np.save(os.path.join(base_dir, 'val_labels_num.npy'), val_labels_num)\n",
    "np.save(os.path.join(base_dir, 'val_labels_encoded.npy'), val_labels_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4b827",
   "metadata": {
    "papermill": {
     "duration": 0.06523,
     "end_time": "2023-12-07T18:45:00.652616",
     "exception": false,
     "start_time": "2023-12-07T18:45:00.587386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4114693,
     "sourceId": 7131655,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 2323,
     "sourceId": 3174,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 129.610014,
   "end_time": "2023-12-07T18:45:03.576770",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-07T18:42:53.966756",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
